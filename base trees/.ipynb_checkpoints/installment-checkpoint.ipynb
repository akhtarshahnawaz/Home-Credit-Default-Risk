{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"installment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from time import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesheet = [time()]\n",
    "def timer(statement):\n",
    "    global timesheet\n",
    "    timesheet.append(time())\n",
    "    print statement+\" :\", (timesheet[-1]-timesheet[-2]),\"seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "installment_features = pd.read_csv(\"../extractor/csv/installment_features_V1.csv\").dropna(axis=1, how=\"all\")\n",
    "\n",
    "train_id = pd.read_csv(\"../data/application_train.csv\", usecols = [\"SK_ID_CURR\",\"TARGET\"])\n",
    "test_id = pd.read_csv(\"../data/application_test.csv\", usecols = [\"SK_ID_CURR\"])\n",
    "\n",
    "installment_features = installment_features.merge(train_id, how = \"left\", on = \"SK_ID_CURR\")\n",
    "\n",
    "train = installment_features.loc[installment_features.TARGET.notnull()].reset_index(drop=True)\n",
    "test = installment_features.loc[installment_features.TARGET.isnull()].reset_index(drop=True)\n",
    "\n",
    "partial_train_id = train[[\"SK_ID_CURR\"]]\n",
    "partial_test_id = test[[\"SK_ID_CURR\"]]\n",
    "target =train.TARGET\n",
    "\n",
    "train.drop([\"SK_ID_CURR\", \"TARGET\"], axis=1, inplace=True)\n",
    "test.drop([\"SK_ID_CURR\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id):\n",
    "    dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "    dval = lgb.Dataset(x_test, label=y_test)\n",
    "    params = {\n",
    "        'num_leaves': 32, #32\n",
    "        'reg_alpha': 0.04, \n",
    "        'n_jobs': -1, \n",
    "        'colsample_bytree': 0.9497036, \n",
    "        'silent': -1, \n",
    "        'subsample_for_bin': 200000, \n",
    "        'subsample_freq': 1, \n",
    "        'learning_rate': 0.02, # 0.02\n",
    "        'boosting_type': 'gbdt', \n",
    "        'nthread': 8, \n",
    "        'min_child_weight': 40, \n",
    "        'min_split_gain': 0.0222415, \n",
    "        'n_estimators': 10000, \n",
    "        'subsample': 0.8715623, \n",
    "        'reg_lambda': 10, \n",
    "        'objective': \"binary\", \n",
    "        'verbose': -1, \n",
    "        'min_child_samples': 20, \n",
    "        'max_depth': 8, #8\n",
    "        'class_weight': None,\n",
    "        \"bagging_seed\" : 3143,\n",
    "        \"seed\":1343,\n",
    "        \"metric\":\"auc\"\n",
    "    }\n",
    "    model = lgb.train(params, dtrain, num_boost_round=5000,valid_sets=[dtrain, dval], early_stopping_rounds=200, verbose_eval=100)\n",
    "    meta_train[test_index] = model.predict(x_test, num_iteration=model.best_iteration or 5000)\n",
    "    meta_test.append(model.predict(test, num_iteration=model.best_iteration or 5000))\n",
    "\n",
    "    # Calculate Feature Importance\n",
    "    global feature_importance\n",
    "    gain = model.feature_importance('gain')\n",
    "    fold_feature_importance = pd.DataFrame({'feature':model.feature_name(), 'split':model.feature_importance('split'), 'gain':100 * gain / gain.sum()})\n",
    "    feature_importance = feature_importance.append(fold_feature_importance, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/lightgbm/engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/lightgbm/basic.py:657: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.658129\tvalid_1's auc: 0.646004\n",
      "[200]\ttraining's auc: 0.677721\tvalid_1's auc: 0.654162\n",
      "[300]\ttraining's auc: 0.693767\tvalid_1's auc: 0.657866\n",
      "[400]\ttraining's auc: 0.707363\tvalid_1's auc: 0.658934\n",
      "[500]\ttraining's auc: 0.71919\tvalid_1's auc: 0.6592\n",
      "[600]\ttraining's auc: 0.73023\tvalid_1's auc: 0.659266\n",
      "[700]\ttraining's auc: 0.740624\tvalid_1's auc: 0.659089\n",
      "Early stopping, best iteration is:\n",
      "[556]\ttraining's auc: 0.7255\tvalid_1's auc: 0.659531\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.657076\tvalid_1's auc: 0.657624\n",
      "[200]\ttraining's auc: 0.676578\tvalid_1's auc: 0.666325\n",
      "[300]\ttraining's auc: 0.692811\tvalid_1's auc: 0.670668\n",
      "[400]\ttraining's auc: 0.706629\tvalid_1's auc: 0.672052\n",
      "[500]\ttraining's auc: 0.718996\tvalid_1's auc: 0.672649\n",
      "[600]\ttraining's auc: 0.729912\tvalid_1's auc: 0.672829\n",
      "[700]\ttraining's auc: 0.739671\tvalid_1's auc: 0.673155\n",
      "[800]\ttraining's auc: 0.749191\tvalid_1's auc: 0.673255\n",
      "[900]\ttraining's auc: 0.758437\tvalid_1's auc: 0.673243\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's auc: 0.741602\tvalid_1's auc: 0.673392\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.658522\tvalid_1's auc: 0.642304\n",
      "[200]\ttraining's auc: 0.678016\tvalid_1's auc: 0.65115\n",
      "[300]\ttraining's auc: 0.694125\tvalid_1's auc: 0.655154\n",
      "[400]\ttraining's auc: 0.707725\tvalid_1's auc: 0.658034\n",
      "[500]\ttraining's auc: 0.720157\tvalid_1's auc: 0.658936\n",
      "[600]\ttraining's auc: 0.730951\tvalid_1's auc: 0.659311\n",
      "[700]\ttraining's auc: 0.741153\tvalid_1's auc: 0.660027\n",
      "[800]\ttraining's auc: 0.750422\tvalid_1's auc: 0.659884\n",
      "[900]\ttraining's auc: 0.759184\tvalid_1's auc: 0.660232\n",
      "[1000]\ttraining's auc: 0.767266\tvalid_1's auc: 0.660133\n",
      "[1100]\ttraining's auc: 0.774856\tvalid_1's auc: 0.659949\n",
      "Early stopping, best iteration is:\n",
      "[948]\ttraining's auc: 0.762966\tvalid_1's auc: 0.660355\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.659324\tvalid_1's auc: 0.636718\n",
      "[200]\ttraining's auc: 0.679145\tvalid_1's auc: 0.645373\n",
      "[300]\ttraining's auc: 0.695121\tvalid_1's auc: 0.649089\n",
      "[400]\ttraining's auc: 0.708669\tvalid_1's auc: 0.651118\n",
      "[500]\ttraining's auc: 0.720883\tvalid_1's auc: 0.651851\n",
      "[600]\ttraining's auc: 0.731703\tvalid_1's auc: 0.652247\n",
      "[700]\ttraining's auc: 0.741316\tvalid_1's auc: 0.652421\n",
      "[800]\ttraining's auc: 0.75093\tvalid_1's auc: 0.652551\n",
      "[900]\ttraining's auc: 0.759932\tvalid_1's auc: 0.652261\n",
      "[1000]\ttraining's auc: 0.767942\tvalid_1's auc: 0.65227\n",
      "Early stopping, best iteration is:\n",
      "[821]\ttraining's auc: 0.752912\tvalid_1's auc: 0.65264\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.657247\tvalid_1's auc: 0.653601\n",
      "[200]\ttraining's auc: 0.676626\tvalid_1's auc: 0.661903\n",
      "[300]\ttraining's auc: 0.692901\tvalid_1's auc: 0.665819\n",
      "[400]\ttraining's auc: 0.706704\tvalid_1's auc: 0.66733\n",
      "[500]\ttraining's auc: 0.718428\tvalid_1's auc: 0.667945\n",
      "[600]\ttraining's auc: 0.730026\tvalid_1's auc: 0.667953\n",
      "[700]\ttraining's auc: 0.740549\tvalid_1's auc: 0.668274\n",
      "[800]\ttraining's auc: 0.749848\tvalid_1's auc: 0.668276\n",
      "[900]\ttraining's auc: 0.758693\tvalid_1's auc: 0.668225\n",
      "[1000]\ttraining's auc: 0.76682\tvalid_1's auc: 0.668237\n",
      "[1100]\ttraining's auc: 0.774462\tvalid_1's auc: 0.668039\n",
      "Early stopping, best iteration is:\n",
      "[953]\ttraining's auc: 0.763188\tvalid_1's auc: 0.668478\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.658673\tvalid_1's auc: 0.640111\n",
      "[200]\ttraining's auc: 0.678505\tvalid_1's auc: 0.647586\n",
      "[300]\ttraining's auc: 0.69449\tvalid_1's auc: 0.650859\n",
      "[400]\ttraining's auc: 0.707616\tvalid_1's auc: 0.652395\n",
      "[500]\ttraining's auc: 0.719525\tvalid_1's auc: 0.652759\n",
      "[600]\ttraining's auc: 0.730876\tvalid_1's auc: 0.653553\n",
      "[700]\ttraining's auc: 0.74104\tvalid_1's auc: 0.653466\n",
      "[800]\ttraining's auc: 0.750539\tvalid_1's auc: 0.653511\n",
      "[900]\ttraining's auc: 0.759071\tvalid_1's auc: 0.653409\n",
      "Early stopping, best iteration is:\n",
      "[788]\ttraining's auc: 0.749382\tvalid_1's auc: 0.653784\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.657609\tvalid_1's auc: 0.645647\n",
      "[200]\ttraining's auc: 0.677619\tvalid_1's auc: 0.654013\n",
      "[300]\ttraining's auc: 0.693912\tvalid_1's auc: 0.658381\n",
      "[400]\ttraining's auc: 0.707527\tvalid_1's auc: 0.659682\n",
      "[500]\ttraining's auc: 0.719349\tvalid_1's auc: 0.660193\n",
      "[600]\ttraining's auc: 0.730264\tvalid_1's auc: 0.660392\n",
      "[700]\ttraining's auc: 0.740448\tvalid_1's auc: 0.660262\n",
      "Early stopping, best iteration is:\n",
      "[588]\ttraining's auc: 0.729\tvalid_1's auc: 0.660668\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.658845\tvalid_1's auc: 0.641022\n",
      "[200]\ttraining's auc: 0.678272\tvalid_1's auc: 0.648943\n",
      "[300]\ttraining's auc: 0.694258\tvalid_1's auc: 0.65257\n",
      "[400]\ttraining's auc: 0.707557\tvalid_1's auc: 0.65462\n",
      "[500]\ttraining's auc: 0.719454\tvalid_1's auc: 0.655727\n",
      "[600]\ttraining's auc: 0.730452\tvalid_1's auc: 0.656205\n",
      "[700]\ttraining's auc: 0.740363\tvalid_1's auc: 0.656361\n",
      "[800]\ttraining's auc: 0.749982\tvalid_1's auc: 0.656229\n",
      "[900]\ttraining's auc: 0.758916\tvalid_1's auc: 0.656017\n",
      "Early stopping, best iteration is:\n",
      "[739]\ttraining's auc: 0.744073\tvalid_1's auc: 0.656461\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.659086\tvalid_1's auc: 0.637406\n",
      "[200]\ttraining's auc: 0.678163\tvalid_1's auc: 0.644864\n",
      "[300]\ttraining's auc: 0.694611\tvalid_1's auc: 0.64885\n",
      "[400]\ttraining's auc: 0.70858\tvalid_1's auc: 0.650114\n",
      "[500]\ttraining's auc: 0.720476\tvalid_1's auc: 0.650664\n",
      "[600]\ttraining's auc: 0.731435\tvalid_1's auc: 0.650672\n",
      "[700]\ttraining's auc: 0.74148\tvalid_1's auc: 0.650911\n",
      "[800]\ttraining's auc: 0.750967\tvalid_1's auc: 0.651164\n",
      "[900]\ttraining's auc: 0.759673\tvalid_1's auc: 0.650721\n",
      "Early stopping, best iteration is:\n",
      "[772]\ttraining's auc: 0.748316\tvalid_1's auc: 0.65135\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.65749\tvalid_1's auc: 0.647121\n",
      "[200]\ttraining's auc: 0.677206\tvalid_1's auc: 0.656869\n",
      "[300]\ttraining's auc: 0.693517\tvalid_1's auc: 0.661243\n",
      "[400]\ttraining's auc: 0.70692\tvalid_1's auc: 0.662737\n",
      "[500]\ttraining's auc: 0.719167\tvalid_1's auc: 0.663342\n",
      "[600]\ttraining's auc: 0.729911\tvalid_1's auc: 0.664411\n",
      "[700]\ttraining's auc: 0.740309\tvalid_1's auc: 0.664798\n",
      "[800]\ttraining's auc: 0.749644\tvalid_1's auc: 0.665161\n",
      "[900]\ttraining's auc: 0.758636\tvalid_1's auc: 0.664972\n",
      "[1000]\ttraining's auc: 0.767266\tvalid_1's auc: 0.665479\n",
      "[1100]\ttraining's auc: 0.775301\tvalid_1's auc: 0.665722\n",
      "[1200]\ttraining's auc: 0.782984\tvalid_1's auc: 0.665564\n",
      "[1300]\ttraining's auc: 0.790031\tvalid_1's auc: 0.665242\n",
      "Early stopping, best iteration is:\n",
      "[1108]\ttraining's auc: 0.775922\tvalid_1's auc: 0.66578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "meta_train = np.zeros(train.shape[0])\n",
    "meta_test = []\n",
    "feature_importance = pd.DataFrame(columns = [\"feature\",\"split\",\"gain\"])\n",
    "\n",
    "kf = StratifiedKFold(n_splits= 10, shuffle=True, random_state=47)\n",
    "for fold_id, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "    x_train, x_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id)\n",
    "\n",
    "partial_test_id[\"TARGET\"] = np.array(meta_test).T.mean(axis=1)\n",
    "partial_train_id[\"TARGET\"] = meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_id = train_id[[\"SK_ID_CURR\"]].merge(partial_train_id, how=\"left\", on=\"SK_ID_CURR\")\n",
    "test_id = test_id[[\"SK_ID_CURR\"]].merge(partial_test_id, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "train_id.to_csv(\"csv/{}_train.csv\".format(model_name), index=False)\n",
    "test_id.to_csv(\"csv/{}_test.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print Feature Importance\n",
    "feature_importance.to_csv(\"csv/{}_all_fi.csv\".format(model_name), index = False)\n",
    "feature_importance = feature_importance.groupby(\"feature\")[[\"gain\",\"split\"]].mean().sort_values('gain', ascending=False).reset_index()\n",
    "\n",
    "plt.figure()\n",
    "feature_importance[['feature','gain']].head(60).plot(kind='barh', x='feature', y='gain', legend=False, figsize=(30, 100))\n",
    "plt.gcf().savefig('csv/{}.png'.format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
