{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"bureau_balance_bb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from time import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesheet = [time()]\n",
    "def timer(statement):\n",
    "    global timesheet\n",
    "    timesheet.append(time())\n",
    "    print statement+\" :\", (timesheet[-1]-timesheet[-2]),\"seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bureau_balance_bb = pd.read_csv(\"../extractor/csv/bureau_features_V1.csv\").dropna(axis=1, how=\"all\")\n",
    "\n",
    "train_id = pd.read_csv(\"../data/application_train.csv\", usecols = [\"SK_ID_CURR\",\"TARGET\"])\n",
    "test_id = pd.read_csv(\"../data/application_test.csv\", usecols = [\"SK_ID_CURR\"])\n",
    "\n",
    "bureau_balance_bb = bureau_balance_bb.merge(train_id, how = \"left\", on = \"SK_ID_CURR\")\n",
    "\n",
    "train = bureau_balance_bb.loc[bureau_balance_bb.TARGET.notnull()].reset_index(drop=True)\n",
    "test = bureau_balance_bb.loc[bureau_balance_bb.TARGET.isnull()].reset_index(drop=True)\n",
    "\n",
    "partial_train_id = train[[\"SK_ID_CURR\"]]\n",
    "partial_test_id = test[[\"SK_ID_CURR\"]]\n",
    "target =train.TARGET\n",
    "\n",
    "train.drop([\"SK_ID_CURR\", \"TARGET\"], axis=1, inplace=True)\n",
    "test.drop([\"SK_ID_CURR\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id):\n",
    "    dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "    dval = lgb.Dataset(x_test, label=y_test)\n",
    "    params = {\n",
    "        'num_leaves': 32, #32\n",
    "        'reg_alpha': 0.04, \n",
    "        'n_jobs': -1, \n",
    "        'colsample_bytree': 0.9497036, \n",
    "        'silent': -1, \n",
    "        'subsample_for_bin': 200000, \n",
    "        'subsample_freq': 1, \n",
    "        'learning_rate': 0.02, # 0.02\n",
    "        'boosting_type': 'gbdt', \n",
    "        'nthread': 8, \n",
    "        'min_child_weight': 40, \n",
    "        'min_split_gain': 0.0222415, \n",
    "        'n_estimators': 10000, \n",
    "        'subsample': 0.8715623, \n",
    "        'reg_lambda': 10, \n",
    "        'objective': \"binary\", \n",
    "        'verbose': -1, \n",
    "        'min_child_samples': 20, \n",
    "        'max_depth': 8, #8\n",
    "        'class_weight': None,\n",
    "        \"bagging_seed\" : 3143,\n",
    "        \"seed\":1343,\n",
    "        \"metric\":\"auc\"\n",
    "    }\n",
    "    model = lgb.train(params, dtrain, num_boost_round=5000,valid_sets=[dtrain, dval], early_stopping_rounds=200, verbose_eval=100)\n",
    "    meta_train[test_index] = model.predict(x_test, num_iteration=model.best_iteration or 5000)\n",
    "    meta_test.append(model.predict(test, num_iteration=model.best_iteration or 5000))\n",
    "\n",
    "    # Calculate Feature Importance\n",
    "    global feature_importance\n",
    "    gain = model.feature_importance('gain')\n",
    "    fold_feature_importance = pd.DataFrame({'feature':model.feature_name(), 'split':model.feature_importance('split'), 'gain':100 * gain / gain.sum()})\n",
    "    feature_importance = feature_importance.append(fold_feature_importance, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/lightgbm/engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/lightgbm/basic.py:657: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.666089\tvalid_1's auc: 0.652104\n",
      "[200]\ttraining's auc: 0.686227\tvalid_1's auc: 0.660826\n",
      "[300]\ttraining's auc: 0.701515\tvalid_1's auc: 0.665061\n",
      "[400]\ttraining's auc: 0.713261\tvalid_1's auc: 0.66677\n",
      "[500]\ttraining's auc: 0.722913\tvalid_1's auc: 0.667132\n",
      "[600]\ttraining's auc: 0.73186\tvalid_1's auc: 0.667231\n",
      "[700]\ttraining's auc: 0.740355\tvalid_1's auc: 0.667604\n",
      "[800]\ttraining's auc: 0.748088\tvalid_1's auc: 0.667263\n",
      "Early stopping, best iteration is:\n",
      "[699]\ttraining's auc: 0.740285\tvalid_1's auc: 0.66762\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.665232\tvalid_1's auc: 0.658992\n",
      "[200]\ttraining's auc: 0.685855\tvalid_1's auc: 0.667842\n",
      "[300]\ttraining's auc: 0.701078\tvalid_1's auc: 0.671627\n",
      "[400]\ttraining's auc: 0.712981\tvalid_1's auc: 0.67284\n",
      "[500]\ttraining's auc: 0.723017\tvalid_1's auc: 0.672972\n",
      "[600]\ttraining's auc: 0.732216\tvalid_1's auc: 0.673081\n",
      "[700]\ttraining's auc: 0.740833\tvalid_1's auc: 0.673264\n",
      "[800]\ttraining's auc: 0.748918\tvalid_1's auc: 0.672684\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttraining's auc: 0.740521\tvalid_1's auc: 0.673331\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.666283\tvalid_1's auc: 0.644399\n",
      "[200]\ttraining's auc: 0.687154\tvalid_1's auc: 0.655762\n",
      "[300]\ttraining's auc: 0.702576\tvalid_1's auc: 0.659522\n",
      "[400]\ttraining's auc: 0.714182\tvalid_1's auc: 0.660957\n",
      "[500]\ttraining's auc: 0.723811\tvalid_1's auc: 0.661332\n",
      "[600]\ttraining's auc: 0.733019\tvalid_1's auc: 0.660981\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's auc: 0.723292\tvalid_1's auc: 0.661446\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.666537\tvalid_1's auc: 0.648489\n",
      "[200]\ttraining's auc: 0.686337\tvalid_1's auc: 0.659311\n",
      "[300]\ttraining's auc: 0.701338\tvalid_1's auc: 0.66588\n",
      "[400]\ttraining's auc: 0.712572\tvalid_1's auc: 0.668618\n",
      "[500]\ttraining's auc: 0.722364\tvalid_1's auc: 0.669412\n",
      "[600]\ttraining's auc: 0.731576\tvalid_1's auc: 0.670173\n",
      "[700]\ttraining's auc: 0.740099\tvalid_1's auc: 0.670168\n",
      "[800]\ttraining's auc: 0.747782\tvalid_1's auc: 0.670475\n",
      "[900]\ttraining's auc: 0.755235\tvalid_1's auc: 0.670503\n",
      "[1000]\ttraining's auc: 0.762558\tvalid_1's auc: 0.670555\n",
      "Early stopping, best iteration is:\n",
      "[872]\ttraining's auc: 0.753194\tvalid_1's auc: 0.670692\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.664924\tvalid_1's auc: 0.652675\n",
      "[200]\ttraining's auc: 0.685728\tvalid_1's auc: 0.66505\n",
      "[300]\ttraining's auc: 0.700185\tvalid_1's auc: 0.670097\n",
      "[400]\ttraining's auc: 0.711646\tvalid_1's auc: 0.672777\n",
      "[500]\ttraining's auc: 0.721751\tvalid_1's auc: 0.673313\n",
      "[600]\ttraining's auc: 0.730608\tvalid_1's auc: 0.673685\n",
      "[700]\ttraining's auc: 0.738817\tvalid_1's auc: 0.674022\n",
      "[800]\ttraining's auc: 0.746303\tvalid_1's auc: 0.67381\n",
      "[900]\ttraining's auc: 0.754008\tvalid_1's auc: 0.673726\n",
      "Early stopping, best iteration is:\n",
      "[734]\ttraining's auc: 0.741339\tvalid_1's auc: 0.674227\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.66459\tvalid_1's auc: 0.657067\n",
      "[200]\ttraining's auc: 0.685588\tvalid_1's auc: 0.669713\n",
      "[300]\ttraining's auc: 0.700243\tvalid_1's auc: 0.673568\n",
      "[400]\ttraining's auc: 0.711896\tvalid_1's auc: 0.675662\n",
      "[500]\ttraining's auc: 0.722248\tvalid_1's auc: 0.677216\n",
      "[600]\ttraining's auc: 0.731651\tvalid_1's auc: 0.677278\n",
      "[700]\ttraining's auc: 0.739929\tvalid_1's auc: 0.677808\n",
      "[800]\ttraining's auc: 0.747749\tvalid_1's auc: 0.677855\n",
      "[900]\ttraining's auc: 0.755268\tvalid_1's auc: 0.678003\n",
      "[1000]\ttraining's auc: 0.762419\tvalid_1's auc: 0.677864\n",
      "[1100]\ttraining's auc: 0.769215\tvalid_1's auc: 0.677626\n",
      "Early stopping, best iteration is:\n",
      "[918]\ttraining's auc: 0.756681\tvalid_1's auc: 0.678118\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.66533\tvalid_1's auc: 0.650536\n",
      "[200]\ttraining's auc: 0.686942\tvalid_1's auc: 0.659746\n",
      "[300]\ttraining's auc: 0.702011\tvalid_1's auc: 0.663315\n",
      "[400]\ttraining's auc: 0.713321\tvalid_1's auc: 0.664736\n",
      "[500]\ttraining's auc: 0.723365\tvalid_1's auc: 0.665696\n",
      "[600]\ttraining's auc: 0.732264\tvalid_1's auc: 0.665298\n",
      "[700]\ttraining's auc: 0.74073\tvalid_1's auc: 0.665318\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttraining's auc: 0.728936\tvalid_1's auc: 0.665906\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.665279\tvalid_1's auc: 0.655837\n",
      "[200]\ttraining's auc: 0.686294\tvalid_1's auc: 0.666842\n",
      "[300]\ttraining's auc: 0.701113\tvalid_1's auc: 0.671436\n",
      "[400]\ttraining's auc: 0.712286\tvalid_1's auc: 0.672923\n",
      "[500]\ttraining's auc: 0.722584\tvalid_1's auc: 0.67341\n",
      "[600]\ttraining's auc: 0.731311\tvalid_1's auc: 0.673585\n",
      "[700]\ttraining's auc: 0.739962\tvalid_1's auc: 0.673323\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's auc: 0.72547\tvalid_1's auc: 0.673792\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.665371\tvalid_1's auc: 0.651836\n",
      "[200]\ttraining's auc: 0.685697\tvalid_1's auc: 0.6647\n",
      "[300]\ttraining's auc: 0.700402\tvalid_1's auc: 0.670628\n",
      "[400]\ttraining's auc: 0.711819\tvalid_1's auc: 0.672914\n",
      "[500]\ttraining's auc: 0.721744\tvalid_1's auc: 0.674012\n",
      "[600]\ttraining's auc: 0.730819\tvalid_1's auc: 0.674752\n",
      "[700]\ttraining's auc: 0.738877\tvalid_1's auc: 0.675018\n",
      "[800]\ttraining's auc: 0.747089\tvalid_1's auc: 0.675229\n",
      "[900]\ttraining's auc: 0.75477\tvalid_1's auc: 0.675366\n",
      "[1000]\ttraining's auc: 0.761962\tvalid_1's auc: 0.675125\n",
      "[1100]\ttraining's auc: 0.769218\tvalid_1's auc: 0.674949\n",
      "Early stopping, best iteration is:\n",
      "[922]\ttraining's auc: 0.756453\tvalid_1's auc: 0.675467\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.666834\tvalid_1's auc: 0.654884\n",
      "[200]\ttraining's auc: 0.686766\tvalid_1's auc: 0.66453\n",
      "[300]\ttraining's auc: 0.701613\tvalid_1's auc: 0.668786\n",
      "[400]\ttraining's auc: 0.712998\tvalid_1's auc: 0.670358\n",
      "[500]\ttraining's auc: 0.723036\tvalid_1's auc: 0.670816\n",
      "[600]\ttraining's auc: 0.732048\tvalid_1's auc: 0.670979\n",
      "[700]\ttraining's auc: 0.740396\tvalid_1's auc: 0.67086\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's auc: 0.727908\tvalid_1's auc: 0.671172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "meta_train = np.zeros(train.shape[0])\n",
    "meta_test = []\n",
    "feature_importance = pd.DataFrame(columns = [\"feature\",\"split\",\"gain\"])\n",
    "\n",
    "kf = StratifiedKFold(n_splits= 10, shuffle=True, random_state=47)\n",
    "for fold_id, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "    x_train, x_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id)\n",
    "\n",
    "partial_test_id[\"TARGET\"] = np.array(meta_test).T.mean(axis=1)\n",
    "partial_train_id[\"TARGET\"] = meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_id = train_id[[\"SK_ID_CURR\"]].merge(partial_train_id, how=\"left\", on=\"SK_ID_CURR\")\n",
    "test_id = test_id[[\"SK_ID_CURR\"]].merge(partial_test_id, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "train_id.to_csv(\"csv/{}_train.csv\".format(model_name), index=False)\n",
    "test_id.to_csv(\"csv/{}_test.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print Feature Importance\n",
    "feature_importance.to_csv(\"csv/{}_all_fi.csv\".format(model_name), index = False)\n",
    "feature_importance = feature_importance.groupby(\"feature\")[[\"gain\",\"split\"]].mean().sort_values('gain', ascending=False).reset_index()\n",
    "\n",
    "plt.figure()\n",
    "feature_importance[['feature','gain']].head(60).plot(kind='barh', x='feature', y='gain', legend=False, figsize=(30, 100))\n",
    "plt.gcf().savefig('csv/{}.png'.format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
