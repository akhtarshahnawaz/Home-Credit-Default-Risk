{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"with_top500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from time import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init... : 0.000192880630493 seconds\n"
     ]
    }
   ],
   "source": [
    "timesheet = [time()]\n",
    "def timer(statement):\n",
    "    global timesheet\n",
    "    timesheet.append(time())\n",
    "    print statement+\" :\", (timesheet[-1]-timesheet[-2]),\"seconds\"\n",
    "timer(\"Init...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_meta(directory, prefix, modeltype):\n",
    "    m_tr = pd.read_csv(directory+prefix+\"_train.csv\")\n",
    "    m_te = pd.read_csv(directory+prefix+\"_test.csv\")\n",
    "    data = pd.concat([m_tr, m_te], axis=0).reset_index(drop=True)\n",
    "    data.columns = [\"{}_{}_{}\".format(c, prefix, modeltype) if c!=\"SK_ID_CURR\" else c for c in data.columns]\n",
    "    return data\n",
    "\n",
    "def load_neptune(directory, modelname):\n",
    "    m_tr = pd.read_csv(directory+\"lightGBM_out_of_fold_train_predictions.csv\", usecols = [\"SK_ID_CURR\",\"lightGBM_prediction\"])\n",
    "    m_te = pd.read_csv(directory+\"lightGBM_out_of_fold_test_predictions.csv\", usecols = [\"SK_ID_CURR\",\"lightGBM_prediction\"])\n",
    "    m_te = m_te.groupby(\"SK_ID_CURR\")[\"lightGBM_prediction\"].mean().reset_index()\n",
    "    \n",
    "    data = pd.concat([m_tr, m_te], axis=0).reset_index(drop=True)\n",
    "    data.columns = [\"SK_ID_CURR\", \"neptune_{}\".format(modelname)]\n",
    "    return data\n",
    "\n",
    "def join_features(data, features):\n",
    "    for item in features:\n",
    "        data = data.merge(item, how = \"left\", on = \"SK_ID_CURR\")\n",
    "    return data\n",
    "\n",
    "def load_data(datafile):\n",
    "    global important_columns\n",
    "    colnames = [c.replace(\" \",\"_\") for c in pd.read_csv(datafile, nrows= 1).columns]\n",
    "    intersection = list(set(colnames).intersection(set(important_columns)))+[\"SK_ID_CURR\"]\n",
    "\n",
    "    df =  pd.read_csv(datafile, names = colnames, usecols = intersection, skiprows=1).dropna(axis=1, how=\"all\")\n",
    "    timer(\"Loaded {} with shape {} in \".format(datafile.split(\"/\")[-1], df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Feature Importance File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_columns = pd.read_csv(\"../feature selector/importance/shap_importances.csv\")\n",
    "important_columns[\"feature\"] = important_columns[\"feature\"].apply(lambda x: x.replace(\" \",\"_\"))\n",
    "important_columns = important_columns.loc[important_columns.shapely_mean > 0.0].reset_index(drop=True)\n",
    "important_columns = important_columns.sort_values(by = \"shapely_mean\", ascending = False).reset_index(drop=True)\n",
    "important_columns = important_columns.loc[0:500].feature.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded application_features_V2.csv with shape (356255, 75) in  : 8.69935011864 seconds\n",
      "Loaded bureau_features_V1.csv with shape (305811, 84) in  : 10.8587238789 seconds\n",
      "Loaded credit_card_features_V1.csv with shape (103558, 16) in  : 10.5597481728 seconds\n",
      "Loaded installment_features_V1.csv with shape (339587, 100) in  : 34.4210269451 seconds\n",
      "Loaded pos_cash_features_V1.csv with shape (337252, 48) in  : 21.7874219418 seconds\n",
      "Loaded previous_application_features_V1.csv with shape (338857, 93) in  : 23.0144040585 seconds\n",
      "Loaded credit_card_features_V3.csv with shape (103558, 6) in  : 17.0106780529 seconds\n",
      "Loaded installment_features_V3.csv with shape (339587, 69) in  : 29.2455968857 seconds\n",
      "Loaded pos_cash_features_V3.csv with shape (337252, 11) in  : 7.32674598694 seconds\n",
      "Loaded previous_application_features_V3.csv with shape (338857, 9) in  : 8.75980710983 seconds\n"
     ]
    }
   ],
   "source": [
    "applications = load_data(\"../extractor/csv/application_features_V2.csv\")\n",
    "bureau_balance_bb = load_data(\"../extractor/csv/bureau_features_V1.csv\")\n",
    "credit_card_balance = load_data(\"../extractor/csv/credit_card_features_V1.csv\")\n",
    "installment_features = load_data(\"../extractor/csv/installment_features_V1.csv\")\n",
    "pos_cash_balance = load_data(\"../extractor/csv/pos_cash_features_V1.csv\")\n",
    "previous_apps = load_data(\"../extractor/csv/previous_application_features_V1.csv\")\n",
    "\n",
    "credit_card_balance_v3 = load_data(\"../extractor/csv/credit_card_features_V3.csv\")\n",
    "installment_features_v3 = load_data(\"../extractor/csv/installment_features_V3.csv\")\n",
    "pos_cash_balance_v3 = load_data(\"../extractor/csv/pos_cash_features_V3.csv\")\n",
    "previous_apps_v3 = load_data(\"../extractor/csv/previous_application_features_V3.csv\")\n",
    "\n",
    "base_features = [applications, bureau_balance_bb, credit_card_balance, installment_features, pos_cash_balance,previous_apps, credit_card_balance_v3,installment_features_v3,pos_cash_balance_v3, previous_apps_v3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_meta_features = [\n",
    "    load_meta(\"../base trees/csv/\", \"application\", \"trees\"),\n",
    "    load_meta(\"../base trees/csv/\", \"bureau_balance_bb\", \"trees\"),\n",
    "    load_meta(\"../base trees/csv/\", \"credit_card_balance\", \"trees\"),\n",
    "    load_meta(\"../base trees/csv/\", \"installment\", \"trees\"),\n",
    "    load_meta(\"../base trees/csv/\", \"pos_cash_balance\", \"trees\"),\n",
    "    load_meta(\"../base trees/csv/\", \"previous_apps\", \"trees\"),\n",
    "]\n",
    "\n",
    "lr_meta_features = [\n",
    "    load_meta(\"../base lr/csv/\", \"application\", \"lr\"),\n",
    "    load_meta(\"../base lr/csv/\", \"bureau_balance_bb\", \"lr\"),\n",
    "    load_meta(\"../base lr/csv/\", \"credit_card_balance\", \"lr\"),\n",
    "    load_meta(\"../base lr/csv/\", \"installment\", \"lr\"),\n",
    "    load_meta(\"../base lr/csv/\", \"pos_cash_balance\", \"lr\"),\n",
    "    load_meta(\"../base lr/csv/\", \"previous_apps\", \"lr\"),\n",
    "]\n",
    "\n",
    "nb_meta_features = [\n",
    "    load_meta(\"../base nb/csv/\", \"application\", \"nb\"),\n",
    "    load_meta(\"../base nb/csv/\", \"bureau_balance_bb\", \"nb\"),\n",
    "    load_meta(\"../base nb/csv/\", \"credit_card_balance\", \"nb\"),\n",
    "    load_meta(\"../base nb/csv/\", \"installment\", \"nb\"),\n",
    "    load_meta(\"../base nb/csv/\", \"pos_cash_balance\", \"nb\"),\n",
    "    load_meta(\"../base nb/csv/\", \"previous_apps\", \"nb\"),\n",
    "]\n",
    "\n",
    "neptune_features = [\n",
    "    load_neptune(\"../base neptune/m1/csv/\", \"m1\"),\n",
    "    load_neptune(\"../base neptune/m2/csv/\", \"m2\"),\n",
    "    load_neptune(\"../base neptune/m3/csv/\", \"m3\"),\n",
    "    load_neptune(\"../base neptune/m4/csv/\", \"m4\"),\n",
    "]\n",
    "\n",
    "mixture_models = [\n",
    "    load_meta(\"../base mixtures/csv/\", \"knn_on_selected_pca\", \"mixtures\"),\n",
    "    load_meta(\"../base mixtures/csv/\", \"lgbm_on_core_features\", \"mixtures\"),\n",
    "    load_meta(\"../base mixtures/csv/\", \"lgbm_on_gp_features\", \"mixtures\"),\n",
    "    load_meta(\"../base mixtures/csv/\", \"lr_on_core_features\", \"mixtures\"),\n",
    "    load_meta(\"../base mixtures/csv/\", \"nn\", \"mixtures\"),\n",
    "    load_meta(\"../base mixtures/csv/\", \"using_lags_bureau_data\", \"mixtures\"),\n",
    "\n",
    "]\n",
    "\n",
    "l1_features = [\n",
    "    load_meta(\"../l1/csv/\", \"l1_gnb\", \"l1\"),\n",
    "    load_meta(\"../l1/csv/\", \"l1_lr\", \"l1\"),\n",
    "    load_meta(\"../l1/csv/\", \"l1_tree_with_flags\", \"l1\"),\n",
    "    load_meta(\"../l1/csv/\", \"l1_tree_without_flags\", \"l1\"),\n",
    "    load_meta(\"../l1/csv/\", \"tree_with_flags_without_meta\", \"l1\"),\n",
    "    load_meta(\"../l1/csv/\", \"tree_without_flags_without_meta\", \"l1\"),\n",
    "    load_meta(\"../l1/csv/\", \"tree_on_core_features_with_meta\", \"l1\"),\n",
    "]\n",
    "\n",
    "l2_features = [\n",
    "    load_meta(\"../l2/csv/\", \"tree_on_l1_and_basemixtures_neptune_1\", \"l2\"),\n",
    "    load_meta(\"../l2/csv/\", \"tree_on_l1_and_basemixtures_neptune_2\", \"l2\"),\n",
    "]\n",
    "\n",
    "final_models = [\n",
    "    load_meta(\"../final_models/csv/\", \"my500_neptuneselected_meta\", \"final_models\"),\n",
    "    load_meta(\"../final_models/csv/\", \"my500_neptuneselected_nometa\", \"final_models\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/application_train.csv\", usecols = [\"SK_ID_CURR\",\"TARGET\"])\n",
    "test = pd.read_csv(\"../data/application_test.csv\", usecols = [\"SK_ID_CURR\"])\n",
    "\n",
    "data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "data = join_features(data, base_features)\n",
    "data = join_features(data, tree_meta_features)\n",
    "data = join_features(data, lr_meta_features)\n",
    "data = join_features(data, nb_meta_features)\n",
    "data = join_features(data, neptune_features)\n",
    "data = join_features(data, mixture_models)\n",
    "data = join_features(data, l1_features)\n",
    "data = join_features(data, l2_features)\n",
    "data = join_features(data, final_models)\n",
    "\n",
    "del base_features,applications, bureau_balance_bb, credit_card_balance, installment_features, pos_cash_balance,previous_apps, credit_card_balance_v3,installment_features_v3,pos_cash_balance_v3, previous_apps_v3\n",
    "gc.collect()\n",
    "\n",
    "train = data.loc[data.TARGET.notnull()].reset_index(drop=True)\n",
    "test = data.loc[data.TARGET.isnull()].reset_index(drop=True)\n",
    "\n",
    "train_id = train[[\"SK_ID_CURR\"]]\n",
    "test_id = test[[\"SK_ID_CURR\"]]\n",
    "test_id_rank = test[[\"SK_ID_CURR\"]]\n",
    "target =train.TARGET\n",
    "\n",
    "train.drop([\"SK_ID_CURR\", \"TARGET\"], axis=1, inplace=True)\n",
    "test.drop([\"SK_ID_CURR\",\"TARGET\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id):\n",
    "    dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "    dval = lgb.Dataset(x_test, label=y_test)\n",
    "    params = {\n",
    "        'num_leaves': 14, #32\n",
    "        'reg_alpha': 0.04, \n",
    "        'n_jobs': -1, \n",
    "        'colsample_bytree': 0.7, \n",
    "        'silent': -1, \n",
    "        'subsample_for_bin': 200000, \n",
    "        'subsample_freq': 1, \n",
    "        'learning_rate': 0.02, # 0.02\n",
    "        'boosting_type': 'gbdt', \n",
    "        'nthread': 6, \n",
    "        'min_child_weight': 40, \n",
    "        'min_split_gain': 0.0222415, \n",
    "        'n_estimators': 10000, \n",
    "        'subsample': 1, \n",
    "        'reg_lambda': 10, \n",
    "        'objective': \"binary\", \n",
    "        'verbose': -1, \n",
    "        'min_child_samples': 20, \n",
    "        'max_depth': 3, #8\n",
    "        'class_weight': None,\n",
    "        \"bagging_seed\" : 3143,\n",
    "        \"seed\":1343,\n",
    "        \"metric\":\"auc\"\n",
    "    }\n",
    "    model = lgb.train(params, dtrain, num_boost_round=5000,valid_sets=[dtrain, dval], early_stopping_rounds=200, verbose_eval=100)\n",
    "    meta_train[test_index] = model.predict(x_test, num_iteration=model.best_iteration or 5000)\n",
    "    meta_test.append(model.predict(test, num_iteration=model.best_iteration or 5000))\n",
    "    \n",
    "    global fold_roc\n",
    "    fold_roc.append(roc_auc_score(y_test, meta_train[test_index]))\n",
    "    # Calculate Feature Importance\n",
    "    global feature_importance\n",
    "    gain = model.feature_importance('gain')\n",
    "    fold_feature_importance = pd.DataFrame({'feature':model.feature_name(), 'split':model.feature_importance('split'), 'gain':100 * gain / gain.sum()})\n",
    "    feature_importance = feature_importance.append(fold_feature_importance, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/lightgbm/engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/lightgbm/basic.py:657: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.800997\tvalid_1's auc: 0.797393\n",
      "[200]\ttraining's auc: 0.802115\tvalid_1's auc: 0.798101\n",
      "[300]\ttraining's auc: 0.803395\tvalid_1's auc: 0.798696\n",
      "[400]\ttraining's auc: 0.804531\tvalid_1's auc: 0.798806\n",
      "[500]\ttraining's auc: 0.80557\tvalid_1's auc: 0.798666\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's auc: 0.804341\tvalid_1's auc: 0.798826\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.801522\tvalid_1's auc: 0.794545\n",
      "[200]\ttraining's auc: 0.802524\tvalid_1's auc: 0.794711\n",
      "[300]\ttraining's auc: 0.803902\tvalid_1's auc: 0.795065\n",
      "[400]\ttraining's auc: 0.805025\tvalid_1's auc: 0.795173\n",
      "[500]\ttraining's auc: 0.806132\tvalid_1's auc: 0.795188\n",
      "[600]\ttraining's auc: 0.8072\tvalid_1's auc: 0.795214\n",
      "[700]\ttraining's auc: 0.80815\tvalid_1's auc: 0.795188\n",
      "Early stopping, best iteration is:\n",
      "[597]\ttraining's auc: 0.807156\tvalid_1's auc: 0.795225\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.80022\tvalid_1's auc: 0.805697\n",
      "[200]\ttraining's auc: 0.801221\tvalid_1's auc: 0.806236\n",
      "[300]\ttraining's auc: 0.802565\tvalid_1's auc: 0.806649\n",
      "[400]\ttraining's auc: 0.803607\tvalid_1's auc: 0.806768\n",
      "[500]\ttraining's auc: 0.804692\tvalid_1's auc: 0.806727\n",
      "[600]\ttraining's auc: 0.805812\tvalid_1's auc: 0.806711\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's auc: 0.803687\tvalid_1's auc: 0.806793\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.801808\tvalid_1's auc: 0.791287\n",
      "[200]\ttraining's auc: 0.802867\tvalid_1's auc: 0.791594\n",
      "[300]\ttraining's auc: 0.804247\tvalid_1's auc: 0.791636\n",
      "[400]\ttraining's auc: 0.805348\tvalid_1's auc: 0.791679\n",
      "[500]\ttraining's auc: 0.806449\tvalid_1's auc: 0.791689\n",
      "[600]\ttraining's auc: 0.807516\tvalid_1's auc: 0.791679\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttraining's auc: 0.805762\tvalid_1's auc: 0.791736\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.800297\tvalid_1's auc: 0.805459\n",
      "[200]\ttraining's auc: 0.801322\tvalid_1's auc: 0.806084\n",
      "[300]\ttraining's auc: 0.802758\tvalid_1's auc: 0.806263\n",
      "[400]\ttraining's auc: 0.803898\tvalid_1's auc: 0.806416\n",
      "[500]\ttraining's auc: 0.804988\tvalid_1's auc: 0.806353\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's auc: 0.803801\tvalid_1's auc: 0.806433\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.801203\tvalid_1's auc: 0.796795\n",
      "[200]\ttraining's auc: 0.802215\tvalid_1's auc: 0.797378\n",
      "[300]\ttraining's auc: 0.803601\tvalid_1's auc: 0.797622\n",
      "[400]\ttraining's auc: 0.804746\tvalid_1's auc: 0.797584\n",
      "[500]\ttraining's auc: 0.805753\tvalid_1's auc: 0.797498\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttraining's auc: 0.804404\tvalid_1's auc: 0.797661\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.800251\tvalid_1's auc: 0.804463\n",
      "[200]\ttraining's auc: 0.80134\tvalid_1's auc: 0.80509\n",
      "[300]\ttraining's auc: 0.802766\tvalid_1's auc: 0.805207\n",
      "[400]\ttraining's auc: 0.803842\tvalid_1's auc: 0.805024\n",
      "Early stopping, best iteration is:\n",
      "[239]\ttraining's auc: 0.801873\tvalid_1's auc: 0.805287\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.800745\tvalid_1's auc: 0.802051\n",
      "[200]\ttraining's auc: 0.801724\tvalid_1's auc: 0.802527\n",
      "[300]\ttraining's auc: 0.803087\tvalid_1's auc: 0.802603\n",
      "[400]\ttraining's auc: 0.804296\tvalid_1's auc: 0.802699\n",
      "[500]\ttraining's auc: 0.805447\tvalid_1's auc: 0.802587\n",
      "Early stopping, best iteration is:\n",
      "[382]\ttraining's auc: 0.804088\tvalid_1's auc: 0.802717\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.800991\tvalid_1's auc: 0.798337\n",
      "[200]\ttraining's auc: 0.802129\tvalid_1's auc: 0.798823\n",
      "[300]\ttraining's auc: 0.803448\tvalid_1's auc: 0.799264\n",
      "[400]\ttraining's auc: 0.804486\tvalid_1's auc: 0.799514\n",
      "[500]\ttraining's auc: 0.805568\tvalid_1's auc: 0.79968\n",
      "[600]\ttraining's auc: 0.80658\tvalid_1's auc: 0.799731\n",
      "[700]\ttraining's auc: 0.807602\tvalid_1's auc: 0.799802\n",
      "[800]\ttraining's auc: 0.80859\tvalid_1's auc: 0.799806\n",
      "[900]\ttraining's auc: 0.80957\tvalid_1's auc: 0.799904\n",
      "[1000]\ttraining's auc: 0.810561\tvalid_1's auc: 0.799878\n",
      "[1100]\ttraining's auc: 0.81153\tvalid_1's auc: 0.799842\n",
      "Early stopping, best iteration is:\n",
      "[934]\ttraining's auc: 0.809961\tvalid_1's auc: 0.799954\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.80083\tvalid_1's auc: 0.799093\n",
      "[200]\ttraining's auc: 0.801864\tvalid_1's auc: 0.800207\n",
      "[300]\ttraining's auc: 0.803209\tvalid_1's auc: 0.800814\n",
      "[400]\ttraining's auc: 0.804272\tvalid_1's auc: 0.800785\n",
      "[500]\ttraining's auc: 0.80532\tvalid_1's auc: 0.800673\n",
      "Early stopping, best iteration is:\n",
      "[334]\ttraining's auc: 0.803578\tvalid_1's auc: 0.80092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ROC: 0.800362250917,  Mean ROC: 0.800555112666, STD AUC: 0.00467517600673\n"
     ]
    }
   ],
   "source": [
    "meta_train = np.zeros(train.shape[0])\n",
    "meta_test = []\n",
    "feature_importance = pd.DataFrame(columns = [\"feature\",\"split\",\"gain\"])\n",
    "fold_roc = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits= 10, shuffle=True, random_state=12323)\n",
    "for fold_id, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "    x_train, x_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id)\n",
    "\n",
    "test_id[\"TARGET\"] = np.array(meta_test).T.mean(axis=1)\n",
    "test_id_rank[\"TARGET\"] = pd.DataFrame(np.array(meta_test).T).rank(pct = True).mean(axis=1)\n",
    "train_id[\"TARGET\"] = meta_train\n",
    "\n",
    "print \"Overall ROC: {},  Mean ROC: {}, STD AUC: {}\".format(roc_auc_score(target, meta_train), np.mean(fold_roc), np.std(fold_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_id.to_csv(\"csv/{}_train.csv\".format(model_name), index=False)\n",
    "test_id.to_csv(\"csv/{}_test.csv\".format(model_name), index=False)\n",
    "test_id_rank.to_csv(\"csv/{}_rank_test.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
