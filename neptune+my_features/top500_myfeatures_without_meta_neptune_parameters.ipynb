{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"top500_myfeatures_without_meta_neptune_parameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from time import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init... : 0.000194072723389 seconds\n"
     ]
    }
   ],
   "source": [
    "timesheet = [time()]\n",
    "def timer(statement):\n",
    "    global timesheet\n",
    "    timesheet.append(time())\n",
    "    print statement+\" :\", (timesheet[-1]-timesheet[-2]),\"seconds\"\n",
    "timer(\"Init...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_meta(directory, prefix, modeltype):\n",
    "    m_tr = pd.read_csv(directory+prefix+\"_train.csv\")\n",
    "    m_te = pd.read_csv(directory+prefix+\"_test.csv\")\n",
    "    data = pd.concat([m_tr, m_te], axis=0).reset_index(drop=True)\n",
    "    data.columns = [\"{}_{}_{}\".format(c, prefix, modeltype) if c!=\"SK_ID_CURR\" else c for c in data.columns]\n",
    "    return data\n",
    "\n",
    "def join_features(data, features):\n",
    "    for item in features:\n",
    "        data = data.merge(item, how = \"left\", on = \"SK_ID_CURR\")\n",
    "    return data\n",
    "\n",
    "def load_data(datafile):\n",
    "    global important_columns\n",
    "    colnames = [c.replace(\" \",\"_\") for c in pd.read_csv(datafile, nrows= 1).columns]\n",
    "    intersection = list(set(colnames).intersection(set(important_columns)))+[\"SK_ID_CURR\"]\n",
    "\n",
    "    df =  pd.read_csv(datafile, names = colnames, usecols = intersection, skiprows=1).dropna(axis=1, how=\"all\")\n",
    "    timer(\"Loaded {} with shape {} in \".format(datafile.split(\"/\")[-1], df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Feature Importance File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_columns = pd.read_csv(\"../feature selector/importance/shap_importances.csv\")\n",
    "important_columns[\"feature\"] = important_columns[\"feature\"].apply(lambda x: x.replace(\" \",\"_\"))\n",
    "important_columns = important_columns.loc[important_columns.shapely_mean > 0.0].reset_index(drop=True)\n",
    "important_columns = important_columns.sort_values(by = \"shapely_mean\", ascending = False).reset_index(drop=True)\n",
    "important_columns = important_columns.loc[0:500].feature.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded application_features_V2.csv with shape (356255, 75) in  : 8.24644303322 seconds\n",
      "Loaded bureau_features_V1.csv with shape (305811, 84) in  : 10.4484648705 seconds\n",
      "Loaded credit_card_features_V1.csv with shape (103558, 16) in  : 10.4234790802 seconds\n",
      "Loaded installment_features_V1.csv with shape (339587, 100) in  : 33.1940031052 seconds\n",
      "Loaded pos_cash_features_V1.csv with shape (337252, 48) in  : 21.1468048096 seconds\n",
      "Loaded previous_application_features_V1.csv with shape (338857, 93) in  : 22.1169970036 seconds\n",
      "Loaded credit_card_features_V3.csv with shape (103558, 6) in  : 17.1201350689 seconds\n",
      "Loaded installment_features_V3.csv with shape (339587, 69) in  : 28.0712220669 seconds\n",
      "Loaded pos_cash_features_V3.csv with shape (337252, 11) in  : 7.09369492531 seconds\n",
      "Loaded previous_application_features_V3.csv with shape (338857, 9) in  : 8.54292702675 seconds\n"
     ]
    }
   ],
   "source": [
    "applications = load_data(\"../extractor/csv/application_features_V2.csv\")\n",
    "bureau_balance_bb = load_data(\"../extractor/csv/bureau_features_V1.csv\")\n",
    "credit_card_balance = load_data(\"../extractor/csv/credit_card_features_V1.csv\")\n",
    "installment_features = load_data(\"../extractor/csv/installment_features_V1.csv\")\n",
    "pos_cash_balance = load_data(\"../extractor/csv/pos_cash_features_V1.csv\")\n",
    "previous_apps = load_data(\"../extractor/csv/previous_application_features_V1.csv\")\n",
    "\n",
    "credit_card_balance_v3 = load_data(\"../extractor/csv/credit_card_features_V3.csv\")\n",
    "installment_features_v3 = load_data(\"../extractor/csv/installment_features_V3.csv\")\n",
    "pos_cash_balance_v3 = load_data(\"../extractor/csv/pos_cash_features_V3.csv\")\n",
    "previous_apps_v3 = load_data(\"../extractor/csv/previous_application_features_V3.csv\")\n",
    "\n",
    "base_features = [applications, bureau_balance_bb, credit_card_balance, installment_features, pos_cash_balance,previous_apps, credit_card_balance_v3,installment_features_v3,pos_cash_balance_v3, previous_apps_v3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/application_train.csv\", usecols = [\"SK_ID_CURR\",\"TARGET\"])\n",
    "test = pd.read_csv(\"../data/application_test.csv\", usecols = [\"SK_ID_CURR\"])\n",
    "\n",
    "neptune_train = pd.read_csv(\"../neptune extractor/data/train.csv\")\n",
    "neptune_test = pd.read_csv(\"../neptune extractor/data/test.csv\")\n",
    "\n",
    "train = pd.concat([train, neptune_train], axis=1)\n",
    "test = pd.concat([test, neptune_test], axis=1)\n",
    "\n",
    "del neptune_train, neptune_test\n",
    "gc.collect()\n",
    "\n",
    "data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "data = join_features(data, base_features)\n",
    "del base_features,applications, bureau_balance_bb, credit_card_balance, installment_features, pos_cash_balance,previous_apps, credit_card_balance_v3,installment_features_v3,pos_cash_balance_v3, previous_apps_v3\n",
    "gc.collect()\n",
    "\n",
    "train = data.loc[data.TARGET.notnull()].reset_index(drop=True)\n",
    "test = data.loc[data.TARGET.isnull()].reset_index(drop=True)\n",
    "\n",
    "train_id = train[[\"SK_ID_CURR\"]]\n",
    "test_id = test[[\"SK_ID_CURR\"]]\n",
    "test_id_rank = test[[\"SK_ID_CURR\"]]\n",
    "target =train.TARGET\n",
    "\n",
    "train.drop([\"SK_ID_CURR\", \"TARGET\"], axis=1, inplace=True)\n",
    "test.drop([\"SK_ID_CURR\",\"TARGET\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id):\n",
    "    dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "    dval = lgb.Dataset(x_test, label=y_test)\n",
    "    params = {\n",
    "        'num_leaves': 30, #32\n",
    "        'reg_alpha': 0.0, \n",
    "        'colsample_bytree': 0.05, \n",
    "        'subsample_freq': 1, \n",
    "        'learning_rate': 0.02, # 0.02\n",
    "        'boosting_type': 'gbdt', \n",
    "        'nthread': 16, \n",
    "        'min_split_gain': 0.5, \n",
    "        'n_estimators': 10000, \n",
    "        'subsample': 1, \n",
    "        'reg_lambda': 100, \n",
    "        'objective': \"binary\", \n",
    "        'min_child_samples': 70, \n",
    "        'max_depth': -1,\n",
    "        'class_weight': None,\n",
    "        \"bagging_seed\" : 3143,\n",
    "        \"seed\":1343,\n",
    "        \"metric\":\"auc\",\n",
    "        \"is_unbalance\": False,\n",
    "        \"scale_pos_weight\": 1,\n",
    "        \"max_bin\":300\n",
    "    }\n",
    "    model = lgb.train(params, dtrain, num_boost_round=5000,valid_sets=[dtrain, dval], early_stopping_rounds=100, verbose_eval=100)\n",
    "    meta_train[test_index] = model.predict(x_test, num_iteration=model.best_iteration or 5000)\n",
    "    meta_test.append(model.predict(test, num_iteration=model.best_iteration or 5000))\n",
    "    \n",
    "    global fold_roc\n",
    "    fold_roc.append(roc_auc_score(y_test, meta_train[test_index]))\n",
    "    # Calculate Feature Importance\n",
    "    global feature_importance\n",
    "    gain = model.feature_importance('gain')\n",
    "    fold_feature_importance = pd.DataFrame({'feature':model.feature_name(), 'split':model.feature_importance('split'), 'gain':100 * gain / gain.sum()})\n",
    "    feature_importance = feature_importance.append(fold_feature_importance, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/lightgbm/engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.757293\tvalid_1's auc: 0.753131\n",
      "[200]\ttraining's auc: 0.778447\tvalid_1's auc: 0.767729\n",
      "[300]\ttraining's auc: 0.793469\tvalid_1's auc: 0.777753\n",
      "[400]\ttraining's auc: 0.804097\tvalid_1's auc: 0.783811\n",
      "[500]\ttraining's auc: 0.812424\tvalid_1's auc: 0.787579\n",
      "[600]\ttraining's auc: 0.819166\tvalid_1's auc: 0.789974\n",
      "[700]\ttraining's auc: 0.825259\tvalid_1's auc: 0.791705\n",
      "[800]\ttraining's auc: 0.830823\tvalid_1's auc: 0.793086\n",
      "[900]\ttraining's auc: 0.835839\tvalid_1's auc: 0.794021\n",
      "[1000]\ttraining's auc: 0.84052\tvalid_1's auc: 0.794824\n",
      "[1100]\ttraining's auc: 0.8449\tvalid_1's auc: 0.7954\n",
      "[1200]\ttraining's auc: 0.849204\tvalid_1's auc: 0.795929\n",
      "[1300]\ttraining's auc: 0.853164\tvalid_1's auc: 0.796377\n",
      "[1400]\ttraining's auc: 0.856965\tvalid_1's auc: 0.796681\n",
      "[1500]\ttraining's auc: 0.860623\tvalid_1's auc: 0.796914\n",
      "[1600]\ttraining's auc: 0.8641\tvalid_1's auc: 0.797168\n",
      "[1700]\ttraining's auc: 0.867358\tvalid_1's auc: 0.797513\n",
      "[1800]\ttraining's auc: 0.870559\tvalid_1's auc: 0.797693\n",
      "[1900]\ttraining's auc: 0.873588\tvalid_1's auc: 0.797686\n",
      "[2000]\ttraining's auc: 0.876518\tvalid_1's auc: 0.797817\n",
      "[2100]\ttraining's auc: 0.879355\tvalid_1's auc: 0.797904\n",
      "[2200]\ttraining's auc: 0.882094\tvalid_1's auc: 0.797966\n",
      "[2300]\ttraining's auc: 0.884702\tvalid_1's auc: 0.797936\n",
      "Early stopping, best iteration is:\n",
      "[2235]\ttraining's auc: 0.882994\tvalid_1's auc: 0.797976\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.758955\tvalid_1's auc: 0.74471\n",
      "[200]\ttraining's auc: 0.77966\tvalid_1's auc: 0.761154\n",
      "[300]\ttraining's auc: 0.794464\tvalid_1's auc: 0.77137\n",
      "[400]\ttraining's auc: 0.804785\tvalid_1's auc: 0.777805\n",
      "[500]\ttraining's auc: 0.812993\tvalid_1's auc: 0.781877\n",
      "[600]\ttraining's auc: 0.81976\tvalid_1's auc: 0.784545\n",
      "[700]\ttraining's auc: 0.825867\tvalid_1's auc: 0.786678\n",
      "[800]\ttraining's auc: 0.831298\tvalid_1's auc: 0.788266\n",
      "[900]\ttraining's auc: 0.836379\tvalid_1's auc: 0.789511\n",
      "[1000]\ttraining's auc: 0.841164\tvalid_1's auc: 0.790447\n",
      "[1100]\ttraining's auc: 0.845608\tvalid_1's auc: 0.791213\n",
      "[1200]\ttraining's auc: 0.849878\tvalid_1's auc: 0.791948\n",
      "[1300]\ttraining's auc: 0.853924\tvalid_1's auc: 0.792465\n",
      "[1400]\ttraining's auc: 0.857642\tvalid_1's auc: 0.79292\n",
      "[1500]\ttraining's auc: 0.861167\tvalid_1's auc: 0.793221\n",
      "[1600]\ttraining's auc: 0.86462\tvalid_1's auc: 0.793437\n",
      "[1700]\ttraining's auc: 0.867962\tvalid_1's auc: 0.793715\n",
      "[1800]\ttraining's auc: 0.871106\tvalid_1's auc: 0.793897\n",
      "[1900]\ttraining's auc: 0.874122\tvalid_1's auc: 0.794129\n",
      "[2000]\ttraining's auc: 0.877004\tvalid_1's auc: 0.794407\n",
      "[2100]\ttraining's auc: 0.879842\tvalid_1's auc: 0.794478\n",
      "Early stopping, best iteration is:\n",
      "[2063]\ttraining's auc: 0.878781\tvalid_1's auc: 0.794505\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.756494\tvalid_1's auc: 0.752631\n",
      "[200]\ttraining's auc: 0.778657\tvalid_1's auc: 0.768706\n",
      "[300]\ttraining's auc: 0.793761\tvalid_1's auc: 0.777872\n",
      "[400]\ttraining's auc: 0.8042\tvalid_1's auc: 0.78295\n",
      "[500]\ttraining's auc: 0.812518\tvalid_1's auc: 0.786341\n",
      "[600]\ttraining's auc: 0.81938\tvalid_1's auc: 0.788739\n",
      "[700]\ttraining's auc: 0.825558\tvalid_1's auc: 0.79054\n",
      "[800]\ttraining's auc: 0.831231\tvalid_1's auc: 0.791845\n",
      "[900]\ttraining's auc: 0.836319\tvalid_1's auc: 0.792747\n",
      "[1000]\ttraining's auc: 0.841129\tvalid_1's auc: 0.793581\n",
      "[1100]\ttraining's auc: 0.845546\tvalid_1's auc: 0.7942\n",
      "[1200]\ttraining's auc: 0.849807\tvalid_1's auc: 0.794588\n",
      "[1300]\ttraining's auc: 0.853833\tvalid_1's auc: 0.794977\n",
      "[1400]\ttraining's auc: 0.857657\tvalid_1's auc: 0.79541\n",
      "[1500]\ttraining's auc: 0.861371\tvalid_1's auc: 0.795604\n",
      "[1600]\ttraining's auc: 0.864847\tvalid_1's auc: 0.795744\n",
      "[1700]\ttraining's auc: 0.868113\tvalid_1's auc: 0.795771\n",
      "[1800]\ttraining's auc: 0.87135\tvalid_1's auc: 0.795881\n",
      "[1900]\ttraining's auc: 0.87441\tvalid_1's auc: 0.796038\n",
      "[2000]\ttraining's auc: 0.877257\tvalid_1's auc: 0.796118\n",
      "[2100]\ttraining's auc: 0.880154\tvalid_1's auc: 0.796188\n",
      "[2200]\ttraining's auc: 0.882808\tvalid_1's auc: 0.79632\n",
      "[2300]\ttraining's auc: 0.885504\tvalid_1's auc: 0.796434\n",
      "[2400]\ttraining's auc: 0.888121\tvalid_1's auc: 0.796471\n",
      "[2500]\ttraining's auc: 0.890751\tvalid_1's auc: 0.796375\n",
      "Early stopping, best iteration is:\n",
      "[2403]\ttraining's auc: 0.888192\tvalid_1's auc: 0.796485\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.757667\tvalid_1's auc: 0.749245\n",
      "[200]\ttraining's auc: 0.7788\tvalid_1's auc: 0.765647\n",
      "[300]\ttraining's auc: 0.793577\tvalid_1's auc: 0.776238\n",
      "[400]\ttraining's auc: 0.803785\tvalid_1's auc: 0.782399\n",
      "[500]\ttraining's auc: 0.812029\tvalid_1's auc: 0.786321\n",
      "[600]\ttraining's auc: 0.818932\tvalid_1's auc: 0.788929\n",
      "[700]\ttraining's auc: 0.824974\tvalid_1's auc: 0.790733\n",
      "[800]\ttraining's auc: 0.830587\tvalid_1's auc: 0.792237\n",
      "[900]\ttraining's auc: 0.835648\tvalid_1's auc: 0.793363\n",
      "[1000]\ttraining's auc: 0.84059\tvalid_1's auc: 0.794329\n",
      "[1100]\ttraining's auc: 0.845129\tvalid_1's auc: 0.795024\n",
      "[1200]\ttraining's auc: 0.849402\tvalid_1's auc: 0.795636\n",
      "[1300]\ttraining's auc: 0.85336\tvalid_1's auc: 0.796129\n",
      "[1400]\ttraining's auc: 0.857144\tvalid_1's auc: 0.796538\n",
      "[1500]\ttraining's auc: 0.860744\tvalid_1's auc: 0.796834\n",
      "[1600]\ttraining's auc: 0.864258\tvalid_1's auc: 0.797127\n",
      "[1700]\ttraining's auc: 0.867531\tvalid_1's auc: 0.797414\n",
      "[1800]\ttraining's auc: 0.870763\tvalid_1's auc: 0.797653\n",
      "[1900]\ttraining's auc: 0.873728\tvalid_1's auc: 0.79785\n",
      "[2000]\ttraining's auc: 0.876677\tvalid_1's auc: 0.798038\n",
      "[2100]\ttraining's auc: 0.879461\tvalid_1's auc: 0.798107\n",
      "[2200]\ttraining's auc: 0.882163\tvalid_1's auc: 0.798156\n",
      "[2300]\ttraining's auc: 0.884784\tvalid_1's auc: 0.798179\n",
      "Early stopping, best iteration is:\n",
      "[2271]\ttraining's auc: 0.884024\tvalid_1's auc: 0.798214\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.757719\tvalid_1's auc: 0.74677\n",
      "[200]\ttraining's auc: 0.778539\tvalid_1's auc: 0.764411\n",
      "[300]\ttraining's auc: 0.793373\tvalid_1's auc: 0.775862\n",
      "[400]\ttraining's auc: 0.803681\tvalid_1's auc: 0.782598\n",
      "[500]\ttraining's auc: 0.811929\tvalid_1's auc: 0.786751\n",
      "[600]\ttraining's auc: 0.818715\tvalid_1's auc: 0.789225\n",
      "[700]\ttraining's auc: 0.824916\tvalid_1's auc: 0.79113\n",
      "[800]\ttraining's auc: 0.830558\tvalid_1's auc: 0.792618\n",
      "[900]\ttraining's auc: 0.835643\tvalid_1's auc: 0.793821\n",
      "[1000]\ttraining's auc: 0.840471\tvalid_1's auc: 0.794701\n",
      "[1100]\ttraining's auc: 0.844972\tvalid_1's auc: 0.795257\n",
      "[1200]\ttraining's auc: 0.849312\tvalid_1's auc: 0.795829\n",
      "[1300]\ttraining's auc: 0.853357\tvalid_1's auc: 0.796399\n",
      "[1400]\ttraining's auc: 0.857139\tvalid_1's auc: 0.796767\n",
      "[1500]\ttraining's auc: 0.86076\tvalid_1's auc: 0.797004\n",
      "[1600]\ttraining's auc: 0.864267\tvalid_1's auc: 0.797339\n",
      "[1700]\ttraining's auc: 0.867525\tvalid_1's auc: 0.797717\n",
      "[1800]\ttraining's auc: 0.870751\tvalid_1's auc: 0.798025\n",
      "[1900]\ttraining's auc: 0.873827\tvalid_1's auc: 0.798218\n",
      "[2000]\ttraining's auc: 0.876878\tvalid_1's auc: 0.79822\n",
      "[2100]\ttraining's auc: 0.879698\tvalid_1's auc: 0.798359\n",
      "[2200]\ttraining's auc: 0.882493\tvalid_1's auc: 0.798445\n",
      "[2300]\ttraining's auc: 0.885207\tvalid_1's auc: 0.798469\n",
      "[2400]\ttraining's auc: 0.887845\tvalid_1's auc: 0.798614\n",
      "[2500]\ttraining's auc: 0.890349\tvalid_1's auc: 0.798719\n",
      "[2600]\ttraining's auc: 0.892738\tvalid_1's auc: 0.7989\n",
      "[2700]\ttraining's auc: 0.895182\tvalid_1's auc: 0.79896\n",
      "[2800]\ttraining's auc: 0.897508\tvalid_1's auc: 0.798964\n",
      "Early stopping, best iteration is:\n",
      "[2760]\ttraining's auc: 0.896621\tvalid_1's auc: 0.798991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ROC: 0.797230046805,  Mean ROC: 0.797233860257, STD AUC: 0.00158781100787\n"
     ]
    }
   ],
   "source": [
    "meta_train = np.zeros(train.shape[0])\n",
    "meta_test = []\n",
    "feature_importance = pd.DataFrame(columns = [\"feature\",\"split\",\"gain\"])\n",
    "fold_roc = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits= 5, shuffle=True, random_state=24344)\n",
    "for fold_id, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "    x_train, x_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    model_tree(x_train, x_test, y_train, y_test, test, meta_train, meta_test,train_index, test_index,fold_id)\n",
    "\n",
    "test_id[\"TARGET\"] = np.array(meta_test).T.mean(axis=1)\n",
    "test_id_rank[\"TARGET\"] = pd.DataFrame(np.array(meta_test).T).rank(pct = True).mean(axis=1)\n",
    "train_id[\"TARGET\"] = meta_train\n",
    "\n",
    "print \"Overall ROC: {},  Mean ROC: {}, STD AUC: {}\".format(roc_auc_score(target, meta_train), np.mean(fold_roc), np.std(fold_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.797975549031412,\n",
       " 0.7945047385040882,\n",
       " 0.7964847267982552,\n",
       " 0.7982136126987289,\n",
       " 0.7989906742531752]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_id.to_csv(\"csv/{}_train.csv\".format(model_name), index=False)\n",
    "test_id.to_csv(\"csv/{}_test.csv\".format(model_name), index=False)\n",
    "test_id_rank.to_csv(\"csv/{}_rank_test.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'split'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3bf5880956e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print Feature Importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv/{}_all_fi.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeature_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gain\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sakhtar0092/anaconda2/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mbad_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 raise KeyError(\"Columns not found: {missing}\"\n\u001b[0;32m--> 249\u001b[0;31m                                .format(missing=str(bad_keys)[1:-1]))\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'split'\""
     ]
    }
   ],
   "source": [
    "# Print Feature Importance\n",
    "feature_importance.to_csv(\"csv/{}_all_fi.csv\".format(model_name), index = False)\n",
    "feature_importance = feature_importance.groupby(\"feature\")[[\"gain\",\"split\"]].mean().sort_values('gain', ascending=False).reset_index()\n",
    "\n",
    "plt.figure()\n",
    "feature_importance[['feature','gain']].head(60).plot(kind='barh', x='feature', y='gain', legend=False, figsize=(30, 100))\n",
    "plt.gcf().savefig('csv/{}.png'.format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
